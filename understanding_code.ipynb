{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b74922-240b-4fd7-bc47-445b7e827e62",
   "metadata": {},
   "source": [
    "# Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960ff1e-d90c-4302-8936-02563eda9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\n",
    "bash Miniforge3-Linux-x86_64.sh\n",
    "source ~/miniforge3/bin/activate\n",
    "# mamba activate latentdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49191c0-6131-4165-a7a7-ef68817ffb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba create -n latentdiff python=3.10 -c defaults\n",
    "mamba activate latentdiff\n",
    "\n",
    "eval \"$(mamba shell hook --shell bash)\"\n",
    "# install pytorch according to instructions (use CUDA version for your system)\n",
    "# https://pytorch.org/get-started/\n",
    "# mamba install pytorch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 pytorch-cuda=12.1 -c pytorch -c nvidia -c defaults\n",
    "mamba create -n latentdiff python=3.10 pytorch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "\n",
    "\n",
    "\n",
    "# install pytorch geometric (use CUDA version for your system)\n",
    "# https://pytorch-geometric.readthedocs.io/\n",
    "pip install torch_geometric\n",
    "pip install torch_sparse torch_scatter torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.1+cu118.html\n",
    "\n",
    "# install other libraries (see requirements.txt for versions)\n",
    "pip install lightning==2.4.0 hydra-core==1.* hydra-colorlog\n",
    "mamba install ase==3.23.0  # individually installed due to dependency conflict\n",
    "mamba install matminer==0.9.2  # individually installed due to dependency conflict\n",
    "mamba install smact==2.6 openbabel==3.1.1 jupyterlab pandas seaborn joblib yaml -c conda-forge\n",
    "pip install pyxtal==0.6.7 mofchecker==0.9.6 rdkit==2024.3.5 e3nn==0.5.1 posebusters==0.3.1 download==0.3.5 ipdb wandb rootutils rich pathos p-tqdm einops svgwrite cairosvg reportlab lmdb torchdiffeq huggingface_hub\n",
    "\n",
    "mamba install notebook ipykernel -c conda-forge\n",
    "\n",
    "python -m ipykernel install --user --name=latentdiff --display-name \"Python (latentdiff)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44252de3-e151-4c5f-a122-b822e6fc81ec",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3158c3-2069-4d27-bea5-e1528809c806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/envs/latentdiff/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from src.data.components.preprocessing_utils import preprocess\n",
    "from src.data.mp_20_datamodule import JointDataModule\n",
    "# from src.data.joint_datamodule import JointDataModule\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0811b066-ca9d-4e3b-96e1-78c83d60f558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MP20(InMemoryDataset):\n",
    "    \"\"\"The MP20 dataset from Materials Project, as a PyG InMemoryDataset.\n",
    "\n",
    "    In order to create a torch_geometric.data.InMemoryDataset, you need to implement four fundamental methods:\n",
    "    - InMemoryDataset.raw_file_names(): A list of files in the raw_dir which needs to be found in order to skip the download.\n",
    "    - InMemoryDataset.processed_file_names(): A list of files in the processed_dir which needs to be found in order to skip the processing.\n",
    "    - InMemoryDataset.download(): Downloads raw data into raw_dir.\n",
    "    - InMemoryDataset.process(): Processes raw data and saves it into the processed_dir.\n",
    "\n",
    "    Args:\n",
    "        root (str): Root directory where the dataset should be saved.\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "        pre_filter (callable, optional): A function that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a boolean\n",
    "            value, indicating whether the data object should be included in the\n",
    "            final dataset. (default: :obj:`None`)\n",
    "        force_reload (bool, optional): Whether to re-process the dataset.\n",
    "            (default: :obj:`False`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        pre_filter: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(root, transform, pre_transform, pre_filter, force_reload=force_reload)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        return [\"all.csv\"]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> List[str]:\n",
    "        return [\"mp20.pt\"]\n",
    "\n",
    "    def download(self) -> None:\n",
    "        from huggingface_hub import hf_hub_download\n",
    "\n",
    "        hf_hub_download(\n",
    "            repo_id=\"chaitjo/MP20_ADiT\",\n",
    "            filename=\"raw/all.csv\",\n",
    "            repo_type=\"dataset\",\n",
    "            local_dir=self.root,\n",
    "        )\n",
    "\n",
    "    def process(self) -> None:\n",
    "        if os.path.exists(os.path.join(self.root, \"raw/all.pt\")):\n",
    "            cached_data = torch.load(os.path.join(self.root, \"raw/all.pt\"))\n",
    "        else:\n",
    "            cached_data = preprocess(\n",
    "                os.path.join(self.root, \"raw/all.csv\"),\n",
    "                niggli=True,\n",
    "                primitive=False,\n",
    "                graph_method=\"crystalnn\",\n",
    "                prop_list=[\"formation_energy_per_atom\"],\n",
    "                use_space_group=True,\n",
    "                tol=0.1,\n",
    "                num_workers=32,\n",
    "            )\n",
    "            torch.save(cached_data, os.path.join(self.root, \"raw/all.pt\"))\n",
    "\n",
    "        data_list = []\n",
    "        for data_dict in cached_data:\n",
    "            # extract attributes from data_dict\n",
    "            graph_arrays = data_dict[\"graph_arrays\"]\n",
    "            atom_types = graph_arrays[\"atom_types\"]\n",
    "            frac_coords = graph_arrays[\"frac_coords\"]\n",
    "            cell = graph_arrays[\"cell\"]\n",
    "            lattices = graph_arrays[\"lattices\"]\n",
    "            lengths = graph_arrays[\"lengths\"]\n",
    "            angles = graph_arrays[\"angles\"]\n",
    "            num_atoms = graph_arrays[\"num_atoms\"]\n",
    "\n",
    "            # normalize the lengths of lattice vectors, which makes\n",
    "            # lengths for materials of different sizes at same scale\n",
    "            _lengths = lengths / float(num_atoms) ** (1 / 3)\n",
    "            # convert angles of lattice vectors to be in radians\n",
    "            _angles = np.radians(angles)\n",
    "            # add scaled lengths and angles to graph arrays\n",
    "            graph_arrays[\"length_scaled\"] = _lengths\n",
    "            graph_arrays[\"angles_radians\"] = _angles\n",
    "            graph_arrays[\"lattices_scaled\"] = np.concatenate([_lengths, _angles])\n",
    "\n",
    "            data = Data(\n",
    "                id=data_dict[\"mp_id\"],\n",
    "                atom_types=torch.LongTensor(atom_types),\n",
    "                frac_coords=torch.Tensor(frac_coords),\n",
    "                cell=torch.Tensor(cell).unsqueeze(0),\n",
    "                lattices=torch.Tensor(lattices).unsqueeze(0),\n",
    "                lattices_scaled=torch.Tensor(graph_arrays[\"lattices_scaled\"]).unsqueeze(0),\n",
    "                lengths=torch.Tensor(lengths).view(1, -1),\n",
    "                lengths_scaled=torch.Tensor(graph_arrays[\"length_scaled\"]).view(1, -1),\n",
    "                angles=torch.Tensor(angles).view(1, -1),\n",
    "                angles_radians=torch.Tensor(graph_arrays[\"angles_radians\"]).view(1, -1),\n",
    "                num_atoms=torch.LongTensor([num_atoms]),\n",
    "                num_nodes=torch.LongTensor([num_atoms]),  # special attribute used for PyG batching\n",
    "                token_idx=torch.arange(num_atoms),\n",
    "                dataset_idx=torch.tensor(\n",
    "                    [0], dtype=torch.long\n",
    "                ),  # 0 --> indicates periodic/crystal\n",
    "            )\n",
    "            # 3D coordinates (NOTE do not zero-center prior to graph construction)\n",
    "            data.pos = torch.einsum(\n",
    "                \"bi,bij->bj\",\n",
    "                data.frac_coords,\n",
    "                torch.repeat_interleave(data.cell, data.num_atoms, dim=0),\n",
    "            )\n",
    "            # space group number\n",
    "            data.spacegroup = torch.LongTensor([data_dict[\"spacegroup\"]])\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            data_list.append(data)\n",
    "\n",
    "        self.save(data_list, os.path.join(self.root, \"processed/mp20.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22ef2007-b675-4cd6-a5e4-721658ad2c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp20_dataset = MP20(root=\"data/mp_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9fbcdcd-ab0f-4271-9d86-bfab3b0a4137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp20_train_dataset = mp20_dataset[:27138]\n",
    "mp20_val_dataset = mp20_dataset[27138 : 27138 + 9046]\n",
    "mp20_test_dataset = mp20_dataset[27138 + 9046 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482637ab-425b-4a59-9cf8-4dd24bd03ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp20_train_dataset = mp20_train_dataset[\n",
    "    : int(len(mp20_train_dataset) * 1.0)\n",
    "]\n",
    "mp20_val_dataset = mp20_val_dataset[\n",
    "    : int(len(mp20_val_dataset) * 1.0)\n",
    "]\n",
    "mp20_test_dataset = mp20_test_dataset[\n",
    "    : int(len(mp20_test_dataset) * 1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2972f5-c32c-4709-83b3-a68628b891a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            dataset=mp20_train_dataset,\n",
    "            batch_size=256,\n",
    "            num_workers=8,\n",
    "            pin_memory=False,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb543d2d-923d-4ea3-be1b-aa43bf86eeb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for d in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5afc142-c11d-40bb-bfe8-c2f62411f7d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(id=[256], atom_types=[2643], frac_coords=[2643, 3], cell=[256, 3, 3], lattices=[256, 6], lattices_scaled=[256, 6], lengths=[256, 3], lengths_scaled=[256, 3], angles=[256, 3], angles_radians=[256, 3], num_atoms=[256], token_idx=[2643], dataset_idx=[256], pos=[2643, 3], spacegroup=[256], num_nodes=[1], batch=[2643], ptr=[257])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c03bc-fdb9-4a9c-aa38-e47c0ae6d129",
   "metadata": {},
   "source": [
    "# Model Definination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef085d3d-fa6c-4306-891e-23e040ddec51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hydra import initialize_config_dir, compose\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Initialize Hydra with the config path (absolute or relative to this notebook)\n",
    "config_path = \"/notebooks/Latent_Pretraining_new/all-atom-diffusion-transformer/configs\"  # directory containing train_autoencoder.yaml\n",
    "config_name = \"train_autoencoder.yaml\"\n",
    "\n",
    "with initialize_config_dir(config_dir=config_path, version_base=\"1.3\"):\n",
    "    cfg = compose(config_name=config_name)\n",
    "\n",
    "# Now you can access config parameters\n",
    "# print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2826ffcf-3910-4ff3-b6ba-7105811f6992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.models.vae_module import VariationalAutoencoderLitModule\n",
    "from src.models.encoders.transformer import TransformerEncoder\n",
    "from src.models.decoders.transformer import TransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc5ccc2b-0450-404a-b68a-c4f1959b5799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(max_num_elements=100,d_model=512,nhead=8,dim_feedforward=2048,activation = \"gelu\", dropout=0.0,norm_first=True,bias=True,num_layers=8)\n",
    "decoder = TransformerDecoder(max_num_elements=100,d_model=512,nhead=8,dim_feedforward=2048,activation = \"gelu\", dropout=0.0,norm_first=True,bias=True,num_layers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "084ac325-c2cf-4d98-b917-709792366b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = hydra.utils.instantiate(cfg.autoencoder_module.optimizer)\n",
    "scheduler = hydra.utils.instantiate(cfg.autoencoder_module.scheduler)\n",
    "scheduler_frequency = cfg.autoencoder_module.scheduler_frequency\n",
    "loss_weights = cfg.autoencoder_module.loss_weights\n",
    "augmentations = cfg.autoencoder_module.augmentations\n",
    "visualization = cfg.autoencoder_module.visualization\n",
    "compile = cfg.autoencoder_module.compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "304e815a-212b-40a0-8884-66c2e3a357ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visualize': True, 'save_dir': '${paths.viz_dir}/'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b60111dd-ab8a-483a-8bef-590bdb1fcaf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae_model = VariationalAutoencoderLitModule(encoder=encoder, decoder=decoder,latent_dim=8,optimizer=optimizer,scheduler=scheduler\n",
    "                                           , scheduler_frequency=scheduler_frequency, loss_weights=loss_weights, augmentations=augmentations,\n",
    "                                           visualization=visualization,compile=compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "effa29a9-c941-4792-944b-da72eab9d8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = vae_model.training_step(d,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eb54b5c-9484-412b-a1fd-199e7b5cab99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46.7873, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f5ee5-535d-4b13-8dfa-f94a9c74f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 python src/train_autoencoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81b385-1286-4e43-86ba-213c842cee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install performer-pytorch downloads torch 2.7.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
